{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5bjzm6hBz_EM"
   },
   "source": [
    "# STEP 0: PROBLEM STATEMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qw0Infukz_EO"
   },
   "source": [
    "- In this case study, you have been provided with images of traffic signs and the goal is to train to classify them\n",
    "- The dataset contains 43 different classes of images. \n",
    "- Classes are as listed below: \n",
    "\n",
    "    - ( 0, b'Speed limit (20m/h)') ( 1, b'Speed limit (30m/h)')\n",
    "    - ( 2, b'Speed limit (50m/h)') ( 3, b'Speed limit (60m/h)')\n",
    "    - ( 4, b'Speed limit (70m/h)') ( 5, b'Speed limit (80m/h)')\n",
    "    - ( 6, b'End of speed limit (80m/h)') ( 7, b'Speed limit (100m/h)')\n",
    "    - ( 8, b'Speed limit (120m/h)') ( 9, b'No passing')\n",
    "    - (10, b'No passing for vehicles over 3.5 metric tons')\n",
    "    - (11, b'Right-of-way at the next intersection') (12, b'Priority road')\n",
    "    - (13, b'Yield') (14, b'Stop') (15, b'No vehicles')\n",
    "    - (16, b'Vehicles over 3.5 metric tons prohibited') (17, b'No entry')\n",
    "    - (18, b'General caution') (19, b'Dangerous curve to the left')\n",
    "    - (20, b'Dangerous curve to the right') (21, b'Double curve')\n",
    "    - (22, b'Bumpy road') (23, b'Slippery road')\n",
    "    - (24, b'Road narrows on the right') (25, b'Road work')\n",
    "    - (26, b'Traffic signals') (27, b'Pedestrians') (28, b'Children crossing')\n",
    "    - (29, b'Bicycles crossing') (30, b'Beware of ice/snow')\n",
    "    - (31, b'Wild animals crossing')\n",
    "    - (32, b'End of all speed and passing limits') (33, b'Turn right ahead')\n",
    "    - (34, b'Turn left ahead') (35, b'Ahead only') (36, b'Go straight or right')\n",
    "    - (37, b'Go straight or left') (38, b'Keep right') (39, b'Keep left')\n",
    "    - (40, b'Roundabout mandatory') (41, b'End of no passing')\n",
    "    - (42, b'End of no passing by vehicles over 3.5 metric tons')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-G4OFGl5z_ER"
   },
   "source": [
    "# STEP 1: IMPORT LIBRARIES AND DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "DA2ZV0QEz_ET"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "0J8fSBsbz_EV"
   },
   "outputs": [],
   "source": [
    "# import libraries \n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import pandas as pd # Import Pandas for data manipulation using dataframes\n",
    "import numpy as np # Import Numpy for data statistical analysis \n",
    "import matplotlib.pyplot as plt # Import matplotlib for data visualisation\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SXp5yj_70W4f",
    "outputId": "92c6eb21-192b-42c5-9d2e-43b2ac5a6cc6"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ee3fUxfJz_EW"
   },
   "outputs": [],
   "source": [
    "# The pickle module implements binary protocols for serializing and de-serializing a Python object structure.\n",
    "with open(\"train.p\", mode='rb') as training_data:\n",
    "    train = pickle.load(training_data)\n",
    "with open(\"valid.p\", mode='rb') as validation_data:\n",
    "    valid = pickle.load(validation_data)\n",
    "with open(\"test.p\", mode='rb') as testing_data:\n",
    "    test = pickle.load(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "uvhOgvXUz_EY"
   },
   "outputs": [],
   "source": [
    "X_train, Y_train = train['features'], train['labels']\n",
    "X_validation, Y_validation = valid['features'], valid['labels']\n",
    "X_test, Y_test = test['features'], test['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FBi1qx69z_Ea",
    "outputId": "8a950450-55d9-4a5e-ae10-0b3b20aece49"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4410"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FscgrdTcz_Ed",
    "outputId": "63c4c7dc-61ce-411f-8c2d-c8b40012759a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34799, 32, 32, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L8_BFbcgz_Ef",
    "outputId": "fbc021d4-67da-48cb-b9db-a44d035d1c0e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34799,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fuXhYtfUz_Eg",
    "outputId": "c6553d69-4261-4b65-f4b4-0c9b536b62a8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N8GRToG2z_Eh",
    "outputId": "96dd3ed1-e729-4f1d-a32d-74a8800a50b8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l4ASgS5Tz_Ej"
   },
   "source": [
    "# STEP 2: IMAGE EXPLORATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "Tyxv-6Wkz_Ek",
    "outputId": "2314a467-0bbb-4b0f-9f76-85186656c534"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 23\n",
    "plt.imshow(X_train[i]) # Show images are not shuffled\n",
    "Y_train[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "jtmU_sJ5z_El",
    "outputId": "3e7bc771-faae-4ce2-8d3b-7c7a9d492084"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 56\n",
    "plt.imshow(X_validation[i]) # Show images are not shuffled\n",
    "Y_validation[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "JviQQimVz_Em",
    "outputId": "04391d1a-856d-45ec-9d90-14a3d9f6bcf1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 123\n",
    "plt.imshow(X_train[i]) # Show images are not shuffled\n",
    "Y_train[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y4-1aYE9z_En"
   },
   "source": [
    "# STEP 3: DATA PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x258da3e7d00>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 842.4x595.44 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a4_dims = (11.7, 8.27)\n",
    "from matplotlib import pyplot\n",
    "fig, ax = pyplot.subplots(figsize=a4_dims)\n",
    "sns.countplot(Y_train, ax =ax, label = \"Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "SmVnl9htz_Eo"
   },
   "outputs": [],
   "source": [
    "## Shuffle the dataset \n",
    "from sklearn.utils import shuffle\n",
    "X_train, Y_train = shuffle(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MCo5elktz_Ep",
    "outputId": "fd9a6d43-9b71-4a76-fd0f-4fcac5efebd7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34799"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5HzQBFnoz_Eq",
    "outputId": "c108edde-4bf7-4147-b0ce-e7d5e6d20898"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34799, 32, 32, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "yi4iZrxAz_Er"
   },
   "outputs": [],
   "source": [
    "X_train = np.sum(X_train/3, axis=3)\n",
    "X_test  = np.sum(X_test/3, axis=3)\n",
    "X_validation  = np.sum(X_validation/3, axis=3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "4YXZ4W-Wz_Et"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from skimage.filters import prewitt_h,prewitt_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1 = []\n",
    "for i in range(len(X_train)):\n",
    "    vertical = prewitt_h(X_train[i])\n",
    "    train_1.append(vertical)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1 = []\n",
    "for i in range(len(X_test)):\n",
    "    vertical = prewitt_h(X_test[i])\n",
    "    test_1.append(vertical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_1 = []\n",
    "for i in range(len(X_validation)):\n",
    "    vertical = prewitt_h(X_validation[i])\n",
    "    validation_1.append(vertical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "mQhT24AAz_Eu"
   },
   "outputs": [],
   "source": [
    "train_data=[]\n",
    "side = 20\n",
    "channels = 1\n",
    "\n",
    "for i in range (0,len(train_1)):\n",
    "        train_image = train_1[i]\n",
    "        image_resized = cv2.resize(train_image, (side, side), interpolation = cv2.INTER_AREA)\n",
    "        train_data.append(np.array(image_resized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "mysbFfXGz_Ev"
   },
   "outputs": [],
   "source": [
    "test_data=[]\n",
    "side = 20\n",
    "channels = 1\n",
    "\n",
    "for i in range (0,len(test_1)):\n",
    "        train_image = test_1[i]\n",
    "        image_resized = cv2.resize(train_image, (side, side), interpolation = cv2.INTER_AREA)\n",
    "        test_data.append(np.array(image_resized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "2Xux2obiz_Ew"
   },
   "outputs": [],
   "source": [
    "validation_data=[]\n",
    "side = 20\n",
    "channels = 1\n",
    "\n",
    "for i in range (0,len(validation_1)):\n",
    "        train_image = validation_1[i]\n",
    "        image_resized = cv2.resize(train_image, (side, side), interpolation = cv2.INTER_AREA)\n",
    "        validation_data.append(np.array(image_resized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "lxBZjggXz_Ey"
   },
   "outputs": [],
   "source": [
    "def clean(data):\n",
    "    data = np.array(data)\n",
    "    data = data.reshape((data.shape[0], 20*20*1))\n",
    "    data = data.astype(float)/255\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "ZEEXJ-NSz_Ez"
   },
   "outputs": [],
   "source": [
    "X_train = clean(train_data)\n",
    "X_test = clean(test_data)\n",
    "X_validation = clean(validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KItkg2Prz_E0",
    "outputId": "00274217-e99c-4c06-b570-65fa17f68a1b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34799, 400)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "Ru4lL9iIz_E1"
   },
   "outputs": [],
   "source": [
    "labels = np.array(Y_validation)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(Y_train)\n",
    "labels = le.fit_transform(Y_test)\n",
    "labels = le.fit_transform(Y_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier( random_state=0)\n",
    "model.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f14BcaRdz_E3"
   },
   "source": [
    "# Predicting Training Set Results \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "R3WIcJbKz_E4"
   },
   "outputs": [],
   "source": [
    "Y_pred_train = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "-TXAesfTz_E4",
    "outputId": "ae176b4c-7e3f-40d4-f72e-471d243dca4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       180\n",
      "           1       1.00      1.00      1.00      1980\n",
      "           2       1.00      1.00      1.00      2010\n",
      "           3       1.00      1.00      1.00      1260\n",
      "           4       1.00      1.00      1.00      1770\n",
      "           5       1.00      1.00      1.00      1650\n",
      "           6       1.00      1.00      1.00       360\n",
      "           7       1.00      1.00      1.00      1290\n",
      "           8       1.00      1.00      1.00      1260\n",
      "           9       1.00      1.00      1.00      1320\n",
      "          10       1.00      1.00      1.00      1800\n",
      "          11       1.00      1.00      1.00      1170\n",
      "          12       1.00      1.00      1.00      1890\n",
      "          13       1.00      1.00      1.00      1920\n",
      "          14       1.00      1.00      1.00       690\n",
      "          15       1.00      1.00      1.00       540\n",
      "          16       1.00      1.00      1.00       360\n",
      "          17       1.00      1.00      1.00       990\n",
      "          18       1.00      1.00      1.00      1080\n",
      "          19       1.00      1.00      1.00       180\n",
      "          20       1.00      1.00      1.00       300\n",
      "          21       1.00      1.00      1.00       270\n",
      "          22       1.00      1.00      1.00       330\n",
      "          23       1.00      1.00      1.00       450\n",
      "          24       1.00      1.00      1.00       240\n",
      "          25       1.00      1.00      1.00      1350\n",
      "          26       1.00      1.00      1.00       540\n",
      "          27       1.00      1.00      1.00       210\n",
      "          28       1.00      1.00      1.00       480\n",
      "          29       1.00      1.00      1.00       240\n",
      "          30       1.00      1.00      1.00       390\n",
      "          31       1.00      1.00      1.00       690\n",
      "          32       1.00      1.00      1.00       210\n",
      "          33       1.00      1.00      1.00       599\n",
      "          34       1.00      1.00      1.00       360\n",
      "          35       1.00      1.00      1.00      1080\n",
      "          36       1.00      1.00      1.00       330\n",
      "          37       1.00      1.00      1.00       180\n",
      "          38       1.00      1.00      1.00      1860\n",
      "          39       1.00      1.00      1.00       270\n",
      "          40       1.00      1.00      1.00       300\n",
      "          41       1.00      1.00      1.00       210\n",
      "          42       1.00      1.00      1.00       210\n",
      "\n",
      "    accuracy                           1.00     34799\n",
      "   macro avg       1.00      1.00      1.00     34799\n",
      "weighted avg       1.00      1.00      1.00     34799\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_train, Y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kYMk51Duz_E5",
    "outputId": "97e22b67-5462-45ee-953d-9330226e2e59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(Y_pred_train, Y_train)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lIAbZXYzz_E6"
   },
   "source": [
    "# Predicting Test Set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "IPRQaVMPz_E7"
   },
   "outputs": [],
   "source": [
    "Y_pred_test = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y79io3PQz_E7",
    "outputId": "16e64616-4644-4fc1-d44a-9023b5b89162"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.62      0.76        60\n",
      "           1       0.84      0.95      0.89       720\n",
      "           2       0.86      0.95      0.90       750\n",
      "           3       0.90      0.92      0.91       450\n",
      "           4       0.96      0.95      0.95       660\n",
      "           5       0.80      0.78      0.79       630\n",
      "           6       0.89      0.73      0.80       150\n",
      "           7       0.94      0.93      0.93       450\n",
      "           8       0.88      0.92      0.90       450\n",
      "           9       0.92      0.99      0.95       480\n",
      "          10       0.92      0.98      0.95       660\n",
      "          11       0.83      0.90      0.86       420\n",
      "          12       0.94      0.96      0.95       690\n",
      "          13       0.97      1.00      0.98       720\n",
      "          14       0.99      0.96      0.98       270\n",
      "          15       0.92      0.92      0.92       210\n",
      "          16       1.00      0.95      0.97       150\n",
      "          17       0.99      0.99      0.99       360\n",
      "          18       0.91      0.86      0.89       390\n",
      "          19       0.97      0.52      0.67        60\n",
      "          20       0.64      0.62      0.63        90\n",
      "          21       0.97      0.42      0.59        90\n",
      "          22       0.94      0.98      0.96       120\n",
      "          23       0.80      0.75      0.78       150\n",
      "          24       1.00      0.56      0.71        90\n",
      "          25       0.90      0.95      0.92       480\n",
      "          26       0.88      0.79      0.84       180\n",
      "          27       1.00      0.50      0.67        60\n",
      "          28       0.91      0.81      0.86       150\n",
      "          29       0.99      0.86      0.92        90\n",
      "          30       0.67      0.56      0.61       150\n",
      "          31       0.79      0.95      0.86       270\n",
      "          32       0.89      0.80      0.84        60\n",
      "          33       0.96      0.98      0.97       210\n",
      "          34       0.99      0.98      0.99       120\n",
      "          35       0.99      0.95      0.97       390\n",
      "          36       0.97      0.93      0.95       120\n",
      "          37       0.98      0.93      0.96        60\n",
      "          38       0.96      0.97      0.96       690\n",
      "          39       0.94      0.83      0.88        90\n",
      "          40       1.00      0.62      0.77        90\n",
      "          41       0.52      0.55      0.54        60\n",
      "          42       0.98      0.56      0.71        90\n",
      "\n",
      "    accuracy                           0.91     12630\n",
      "   macro avg       0.91      0.83      0.86     12630\n",
      "weighted avg       0.91      0.91      0.90     12630\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, Y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jr4G8fcJ565i",
    "outputId": "4a4de01b-8ad7-4738-cbb3-8b5f508ee869"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9057007125890736\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(Y_test, Y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HBuT0I_xz_E8"
   },
   "source": [
    "# Predicting Validation Set Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "IVfrX7xrz_E9"
   },
   "outputs": [],
   "source": [
    "Y_pred_valid = model.predict(X_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oyPZTEYCz_E-",
    "outputId": "b361e299-8605-48e3-8f73-f09f71192520"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.53      0.70        30\n",
      "           1       0.84      0.88      0.86       240\n",
      "           2       0.95      0.88      0.91       240\n",
      "           3       0.86      0.97      0.91       150\n",
      "           4       0.93      0.97      0.95       210\n",
      "           5       0.82      0.80      0.81       210\n",
      "           6       0.75      1.00      0.86        60\n",
      "           7       0.91      0.96      0.94       150\n",
      "           8       0.92      0.90      0.91       150\n",
      "           9       0.97      0.93      0.95       150\n",
      "          10       0.91      1.00      0.95       210\n",
      "          11       0.77      0.93      0.84       150\n",
      "          12       0.82      0.98      0.89       210\n",
      "          13       0.98      1.00      0.99       240\n",
      "          14       1.00      0.99      0.99        90\n",
      "          15       0.96      0.98      0.97        90\n",
      "          16       0.98      0.98      0.98        60\n",
      "          17       0.99      1.00      1.00       120\n",
      "          18       0.78      0.99      0.88       120\n",
      "          19       0.86      0.63      0.73        30\n",
      "          20       0.82      0.47      0.60        60\n",
      "          21       1.00      0.42      0.59        60\n",
      "          22       1.00      0.85      0.92        60\n",
      "          23       0.91      0.82      0.86        60\n",
      "          24       0.00      0.00      0.00        30\n",
      "          25       0.91      0.98      0.95       150\n",
      "          26       0.95      0.97      0.96        60\n",
      "          27       0.81      0.43      0.57        30\n",
      "          28       0.92      1.00      0.96        60\n",
      "          29       0.96      0.83      0.89        30\n",
      "          30       0.75      0.83      0.79        60\n",
      "          31       0.76      1.00      0.86        90\n",
      "          32       0.43      0.33      0.38        30\n",
      "          33       0.99      0.97      0.98        90\n",
      "          34       1.00      1.00      1.00        60\n",
      "          35       0.98      0.98      0.98       120\n",
      "          36       1.00      1.00      1.00        60\n",
      "          37       1.00      1.00      1.00        30\n",
      "          38       0.98      0.96      0.97       210\n",
      "          39       1.00      1.00      1.00        30\n",
      "          40       1.00      0.35      0.52        60\n",
      "          41       1.00      0.50      0.67        30\n",
      "          42       1.00      0.63      0.78        30\n",
      "\n",
      "    accuracy                           0.90      4410\n",
      "   macro avg       0.89      0.83      0.84      4410\n",
      "weighted avg       0.90      0.90      0.89      4410\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_validation, Y_pred_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0mz7S4Fuz_E-",
    "outputId": "721c2242-12a5-483e-cad3-bfd3cab3ef85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9004535147392291\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(Y_validation, Y_pred_valid)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SVM\n",
    "from sklearn import svm\n",
    "model_1 = svm.SVC()\n",
    "model_1.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VStcfRhz69Lv"
   },
   "source": [
    "# Predicting Training Set Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_train = model_1.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.97       180\n",
      "           1       0.99      0.94      0.97      1980\n",
      "           2       0.98      0.96      0.97      2010\n",
      "           3       0.96      0.92      0.94      1260\n",
      "           4       0.94      0.98      0.96      1770\n",
      "           5       0.82      0.97      0.89      1650\n",
      "           6       0.98      0.98      0.98       360\n",
      "           7       0.99      0.91      0.95      1290\n",
      "           8       0.95      0.94      0.95      1260\n",
      "           9       1.00      0.94      0.97      1320\n",
      "          10       0.88      0.99      0.93      1800\n",
      "          11       0.98      0.97      0.97      1170\n",
      "          12       0.94      0.98      0.96      1890\n",
      "          13       0.99      1.00      0.99      1920\n",
      "          14       0.99      1.00      0.99       690\n",
      "          15       1.00      0.97      0.98       540\n",
      "          16       1.00      0.96      0.98       360\n",
      "          17       0.98      0.99      0.99       990\n",
      "          18       0.92      0.97      0.94      1080\n",
      "          19       0.99      0.79      0.88       180\n",
      "          20       0.80      0.87      0.83       300\n",
      "          21       1.00      0.96      0.98       270\n",
      "          22       0.99      1.00      1.00       330\n",
      "          23       0.99      0.90      0.94       450\n",
      "          24       1.00      0.94      0.97       240\n",
      "          25       0.99      0.99      0.99      1350\n",
      "          26       0.96      0.87      0.91       540\n",
      "          27       1.00      0.94      0.97       210\n",
      "          28       1.00      0.87      0.93       480\n",
      "          29       0.99      0.97      0.98       240\n",
      "          30       0.98      0.89      0.93       390\n",
      "          31       0.97      0.95      0.96       690\n",
      "          32       1.00      0.92      0.96       210\n",
      "          33       0.99      0.94      0.97       599\n",
      "          34       1.00      0.96      0.98       360\n",
      "          35       1.00      0.97      0.98      1080\n",
      "          36       0.98      0.99      0.98       330\n",
      "          37       0.99      0.98      0.99       180\n",
      "          38       0.97      1.00      0.98      1860\n",
      "          39       1.00      0.96      0.98       270\n",
      "          40       1.00      0.86      0.92       300\n",
      "          41       1.00      0.94      0.97       210\n",
      "          42       1.00      0.97      0.98       210\n",
      "\n",
      "    accuracy                           0.96     34799\n",
      "   macro avg       0.97      0.95      0.96     34799\n",
      "weighted avg       0.96      0.96      0.96     34799\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_train, Y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9596252765884077\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(Y_pred_train, Y_train)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Test Set Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_test = model_1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.40      0.57        60\n",
      "           1       0.72      0.89      0.80       720\n",
      "           2       0.79      0.87      0.83       750\n",
      "           3       0.64      0.76      0.70       450\n",
      "           4       0.85      0.80      0.82       660\n",
      "           5       0.61      0.76      0.68       630\n",
      "           6       0.82      0.64      0.72       150\n",
      "           7       0.92      0.67      0.78       450\n",
      "           8       0.83      0.82      0.82       450\n",
      "           9       0.93      0.78      0.85       480\n",
      "          10       0.73      0.94      0.82       660\n",
      "          11       0.71      0.82      0.76       420\n",
      "          12       0.67      0.96      0.79       690\n",
      "          13       0.87      0.96      0.91       720\n",
      "          14       0.93      0.87      0.90       270\n",
      "          15       0.92      0.59      0.72       210\n",
      "          16       0.95      0.94      0.95       150\n",
      "          17       0.98      0.93      0.95       360\n",
      "          18       0.80      0.65      0.72       390\n",
      "          19       0.97      0.50      0.66        60\n",
      "          20       0.34      0.31      0.32        90\n",
      "          21       0.96      0.58      0.72        90\n",
      "          22       0.99      0.73      0.84       120\n",
      "          23       0.56      0.33      0.41       150\n",
      "          24       0.93      0.28      0.43        90\n",
      "          25       0.89      0.82      0.85       480\n",
      "          26       0.76      0.84      0.80       180\n",
      "          27       0.82      0.45      0.58        60\n",
      "          28       0.82      0.55      0.66       150\n",
      "          29       0.86      0.73      0.79        90\n",
      "          30       0.56      0.26      0.35       150\n",
      "          31       0.74      0.81      0.77       270\n",
      "          32       0.91      0.72      0.80        60\n",
      "          33       0.88      0.89      0.89       210\n",
      "          34       0.97      0.93      0.95       120\n",
      "          35       0.87      0.65      0.75       390\n",
      "          36       0.93      0.72      0.81       120\n",
      "          37       0.98      0.75      0.85        60\n",
      "          38       0.86      0.93      0.89       690\n",
      "          39       0.92      0.53      0.68        90\n",
      "          40       1.00      0.36      0.52        90\n",
      "          41       0.95      0.62      0.75        60\n",
      "          42       0.89      0.81      0.85        90\n",
      "\n",
      "    accuracy                           0.79     12630\n",
      "   macro avg       0.84      0.70      0.74     12630\n",
      "weighted avg       0.81      0.79      0.79     12630\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, Y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7937450514647665\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(Y_test, Y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Validation Set Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_valid = model_1.predict(X_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.03      0.06        30\n",
      "           1       0.70      0.76      0.73       240\n",
      "           2       0.72      0.76      0.74       240\n",
      "           3       0.69      0.91      0.78       150\n",
      "           4       0.65      0.95      0.77       210\n",
      "           5       0.62      0.70      0.66       210\n",
      "           6       0.60      0.98      0.74        60\n",
      "           7       0.98      0.69      0.81       150\n",
      "           8       0.80      0.72      0.76       150\n",
      "           9       0.90      0.80      0.85       150\n",
      "          10       0.81      0.94      0.87       210\n",
      "          11       0.56      0.90      0.69       150\n",
      "          12       0.65      0.99      0.78       210\n",
      "          13       0.78      0.99      0.87       240\n",
      "          14       0.98      0.93      0.95        90\n",
      "          15       0.94      0.68      0.79        90\n",
      "          16       1.00      0.18      0.31        60\n",
      "          17       1.00      0.90      0.95       120\n",
      "          18       0.78      0.88      0.82       120\n",
      "          19       0.54      0.70      0.61        30\n",
      "          20       0.85      0.28      0.42        60\n",
      "          21       0.60      0.10      0.17        60\n",
      "          22       0.96      0.37      0.53        60\n",
      "          23       0.61      0.47      0.53        60\n",
      "          24       0.00      0.00      0.00        30\n",
      "          25       0.87      0.77      0.82       150\n",
      "          26       0.73      0.93      0.82        60\n",
      "          27       0.00      0.00      0.00        30\n",
      "          28       0.73      0.88      0.80        60\n",
      "          29       0.71      0.17      0.27        30\n",
      "          30       0.76      0.75      0.76        60\n",
      "          31       0.83      0.90      0.86        90\n",
      "          32       0.12      0.07      0.09        30\n",
      "          33       0.98      0.56      0.71        90\n",
      "          34       0.89      0.53      0.67        60\n",
      "          35       0.71      0.72      0.71       120\n",
      "          36       0.97      0.58      0.73        60\n",
      "          37       1.00      0.50      0.67        30\n",
      "          38       0.89      0.98      0.93       210\n",
      "          39       0.95      0.70      0.81        30\n",
      "          40       0.97      0.47      0.63        60\n",
      "          41       1.00      0.37      0.54        30\n",
      "          42       0.67      0.07      0.12        30\n",
      "\n",
      "    accuracy                           0.75      4410\n",
      "   macro avg       0.76      0.62      0.63      4410\n",
      "weighted avg       0.77      0.75      0.73      4410\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_validation, Y_pred_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.753968253968254\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(Y_validation, Y_pred_valid)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "model_2 = GaussianNB()\n",
    "model_2.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Training Set Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_train = model_2.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.69      0.27       180\n",
      "           1       0.64      0.35      0.45      1980\n",
      "           2       0.68      0.38      0.48      2010\n",
      "           3       0.21      0.18      0.19      1260\n",
      "           4       0.39      0.25      0.30      1770\n",
      "           5       0.28      0.20      0.23      1650\n",
      "           6       0.18      0.84      0.30       360\n",
      "           7       0.53      0.17      0.26      1290\n",
      "           8       0.28      0.22      0.25      1260\n",
      "           9       0.78      0.59      0.67      1320\n",
      "          10       0.29      0.42      0.34      1800\n",
      "          11       0.58      0.48      0.52      1170\n",
      "          12       0.80      0.51      0.62      1890\n",
      "          13       0.92      0.62      0.74      1920\n",
      "          14       0.96      0.85      0.90       690\n",
      "          15       0.73      0.50      0.59       540\n",
      "          16       0.68      0.70      0.69       360\n",
      "          17       0.97      0.78      0.86       990\n",
      "          18       0.92      0.28      0.43      1080\n",
      "          19       0.43      0.29      0.35       180\n",
      "          20       0.04      0.84      0.07       300\n",
      "          21       0.34      0.44      0.38       270\n",
      "          22       0.85      0.51      0.64       330\n",
      "          23       0.54      0.34      0.41       450\n",
      "          24       0.83      0.46      0.59       240\n",
      "          25       0.81      0.43      0.56      1350\n",
      "          26       0.41      0.16      0.23       540\n",
      "          27       0.43      0.52      0.47       210\n",
      "          28       0.64      0.43      0.52       480\n",
      "          29       0.26      0.33      0.29       240\n",
      "          30       0.38      0.52      0.44       390\n",
      "          31       0.22      0.41      0.28       690\n",
      "          32       0.86      0.60      0.70       210\n",
      "          33       0.63      0.55      0.59       599\n",
      "          34       0.65      0.72      0.68       360\n",
      "          35       0.71      0.63      0.67      1080\n",
      "          36       0.77      0.74      0.75       330\n",
      "          37       0.90      0.78      0.84       180\n",
      "          38       0.92      0.48      0.63      1860\n",
      "          39       0.99      0.74      0.85       270\n",
      "          40       0.61      0.58      0.60       300\n",
      "          41       0.64      0.71      0.67       210\n",
      "          42       0.25      0.09      0.13       210\n",
      "\n",
      "    accuracy                           0.44     34799\n",
      "   macro avg       0.58      0.49      0.50     34799\n",
      "weighted avg       0.61      0.44      0.49     34799\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_train, Y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4421104054714216\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(Y_pred_train, Y_train)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Test Set Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_test = model_2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.07      0.38      0.11        60\n",
      "           1       0.62      0.32      0.42       720\n",
      "           2       0.47      0.28      0.35       750\n",
      "           3       0.19      0.17      0.18       450\n",
      "           4       0.20      0.11      0.14       660\n",
      "           5       0.13      0.08      0.10       630\n",
      "           6       0.16      0.58      0.25       150\n",
      "           7       0.49      0.17      0.26       450\n",
      "           8       0.43      0.40      0.42       450\n",
      "           9       0.50      0.43      0.46       480\n",
      "          10       0.25      0.35      0.29       660\n",
      "          11       0.34      0.54      0.42       420\n",
      "          12       0.75      0.52      0.61       690\n",
      "          13       0.93      0.68      0.79       720\n",
      "          14       0.92      0.76      0.83       270\n",
      "          15       0.78      0.49      0.60       210\n",
      "          16       0.56      0.62      0.59       150\n",
      "          17       0.98      0.78      0.87       360\n",
      "          18       0.83      0.10      0.18       390\n",
      "          19       0.24      0.13      0.17        60\n",
      "          20       0.01      0.21      0.02        90\n",
      "          21       0.46      0.49      0.48        90\n",
      "          22       0.40      0.14      0.21       120\n",
      "          23       0.08      0.09      0.09       150\n",
      "          24       0.23      0.03      0.06        90\n",
      "          25       0.77      0.46      0.57       480\n",
      "          26       0.43      0.12      0.19       180\n",
      "          27       0.10      0.13      0.11        60\n",
      "          28       0.46      0.21      0.29       150\n",
      "          29       0.01      0.01      0.01        90\n",
      "          30       0.24      0.21      0.22       150\n",
      "          31       0.18      0.31      0.23       270\n",
      "          32       0.95      0.30      0.46        60\n",
      "          33       0.61      0.49      0.54       210\n",
      "          34       0.79      0.93      0.85       120\n",
      "          35       0.39      0.24      0.30       390\n",
      "          36       0.87      0.68      0.76       120\n",
      "          37       0.86      0.52      0.65        60\n",
      "          38       0.89      0.58      0.70       690\n",
      "          39       0.98      0.60      0.74        90\n",
      "          40       0.41      0.51      0.45        90\n",
      "          41       0.26      0.62      0.37        60\n",
      "          42       0.38      0.09      0.14        90\n",
      "\n",
      "    accuracy                           0.37     12630\n",
      "   macro avg       0.48      0.37      0.38     12630\n",
      "weighted avg       0.52      0.37      0.41     12630\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, Y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3737133808392716\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(Y_test, Y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Validation Set Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_valid = model_2.predict(X_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      0.47      0.16        30\n",
      "           1       0.60      0.32      0.42       240\n",
      "           2       0.49      0.40      0.44       240\n",
      "           3       0.50      0.22      0.31       150\n",
      "           4       0.36      0.13      0.19       210\n",
      "           5       0.21      0.10      0.14       210\n",
      "           6       0.18      0.90      0.31        60\n",
      "           7       0.47      0.12      0.19       150\n",
      "           8       0.05      0.02      0.03       150\n",
      "           9       0.33      0.17      0.23       150\n",
      "          10       0.27      0.45      0.34       210\n",
      "          11       0.24      0.27      0.25       150\n",
      "          12       0.77      0.93      0.84       210\n",
      "          13       0.80      0.41      0.54       240\n",
      "          14       0.94      0.80      0.86        90\n",
      "          15       0.89      0.53      0.67        90\n",
      "          16       0.81      0.92      0.86        60\n",
      "          17       1.00      0.97      0.99       120\n",
      "          18       0.73      0.18      0.29       120\n",
      "          19       0.06      0.03      0.04        30\n",
      "          20       0.02      0.33      0.04        60\n",
      "          21       0.14      0.02      0.03        60\n",
      "          22       0.61      0.33      0.43        60\n",
      "          23       0.22      0.25      0.24        60\n",
      "          24       0.00      0.00      0.00        30\n",
      "          25       0.59      0.29      0.39       150\n",
      "          26       0.39      0.30      0.34        60\n",
      "          27       0.00      0.00      0.00        30\n",
      "          28       0.76      0.68      0.72        60\n",
      "          29       0.02      0.03      0.03        30\n",
      "          30       0.02      0.03      0.03        60\n",
      "          31       0.23      0.22      0.23        90\n",
      "          32       0.00      0.00      0.00        30\n",
      "          33       0.59      0.29      0.39        90\n",
      "          34       0.54      0.22      0.31        60\n",
      "          35       0.35      0.46      0.40       120\n",
      "          36       0.80      0.20      0.32        60\n",
      "          37       0.96      0.83      0.89        30\n",
      "          38       0.82      0.46      0.59       210\n",
      "          39       0.84      0.70      0.76        30\n",
      "          40       0.36      0.23      0.28        60\n",
      "          41       0.00      0.00      0.00        30\n",
      "          42       0.00      0.00      0.00        30\n",
      "\n",
      "    accuracy                           0.35      4410\n",
      "   macro avg       0.42      0.33      0.34      4410\n",
      "weighted avg       0.48      0.35      0.38      4410\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_validation, Y_pred_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35374149659863946\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(Y_validation, Y_pred_valid)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model_3 = KNeighborsClassifier()\n",
    "model_3.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Training Set Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_train = model_3.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.88      0.91       180\n",
      "           1       0.95      0.92      0.93      1980\n",
      "           2       0.97      0.90      0.93      2010\n",
      "           3       0.84      0.87      0.85      1260\n",
      "           4       0.89      0.92      0.90      1770\n",
      "           5       0.74      0.92      0.82      1650\n",
      "           6       0.92      0.98      0.95       360\n",
      "           7       0.85      0.94      0.89      1290\n",
      "           8       0.85      0.93      0.89      1260\n",
      "           9       0.98      0.96      0.97      1320\n",
      "          10       0.93      0.95      0.94      1800\n",
      "          11       0.97      0.93      0.95      1170\n",
      "          12       0.99      0.93      0.96      1890\n",
      "          13       0.98      0.99      0.98      1920\n",
      "          14       0.99      0.93      0.96       690\n",
      "          15       0.98      0.90      0.94       540\n",
      "          16       0.99      0.99      0.99       360\n",
      "          17       0.99      0.99      0.99       990\n",
      "          18       0.92      0.96      0.94      1080\n",
      "          19       0.94      0.94      0.94       180\n",
      "          20       0.87      0.95      0.90       300\n",
      "          21       0.96      0.92      0.94       270\n",
      "          22       1.00      0.97      0.99       330\n",
      "          23       0.97      0.94      0.95       450\n",
      "          24       0.96      0.89      0.92       240\n",
      "          25       0.97      0.95      0.96      1350\n",
      "          26       0.92      0.93      0.93       540\n",
      "          27       0.98      0.82      0.89       210\n",
      "          28       0.99      0.94      0.96       480\n",
      "          29       0.98      0.85      0.91       240\n",
      "          30       0.86      0.94      0.90       390\n",
      "          31       0.95      0.97      0.96       690\n",
      "          32       0.88      0.87      0.87       210\n",
      "          33       0.98      0.93      0.96       599\n",
      "          34       0.97      0.94      0.95       360\n",
      "          35       0.99      0.89      0.94      1080\n",
      "          36       0.99      0.91      0.95       330\n",
      "          37       1.00      0.90      0.95       180\n",
      "          38       0.97      0.93      0.95      1860\n",
      "          39       0.99      1.00      0.99       270\n",
      "          40       0.99      0.85      0.92       300\n",
      "          41       0.99      0.92      0.96       210\n",
      "          42       0.98      0.90      0.94       210\n",
      "\n",
      "    accuracy                           0.93     34799\n",
      "   macro avg       0.95      0.93      0.94     34799\n",
      "weighted avg       0.94      0.93      0.93     34799\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_train, Y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9319520675881491\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(Y_pred_train, Y_train)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Test Set Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_test = model_3.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.38      0.35        60\n",
      "           1       0.58      0.43      0.49       720\n",
      "           2       0.61      0.48      0.54       750\n",
      "           3       0.31      0.36      0.34       450\n",
      "           4       0.51      0.59      0.55       660\n",
      "           5       0.28      0.57      0.38       630\n",
      "           6       0.56      0.59      0.58       150\n",
      "           7       0.34      0.52      0.41       450\n",
      "           8       0.43      0.48      0.46       450\n",
      "           9       0.71      0.59      0.64       480\n",
      "          10       0.63      0.78      0.70       660\n",
      "          11       0.63      0.54      0.58       420\n",
      "          12       0.98      0.78      0.87       690\n",
      "          13       0.94      0.94      0.94       720\n",
      "          14       0.96      0.64      0.76       270\n",
      "          15       0.81      0.52      0.64       210\n",
      "          16       0.73      0.99      0.84       150\n",
      "          17       0.98      0.99      0.98       360\n",
      "          18       0.50      0.47      0.48       390\n",
      "          19       0.45      0.53      0.49        60\n",
      "          20       0.36      0.60      0.45        90\n",
      "          21       0.89      0.46      0.60        90\n",
      "          22       0.90      0.86      0.88       120\n",
      "          23       0.47      0.34      0.39       150\n",
      "          24       0.07      0.03      0.04        90\n",
      "          25       0.83      0.74      0.78       480\n",
      "          26       0.58      0.64      0.61       180\n",
      "          27       0.44      0.23      0.30        60\n",
      "          28       0.53      0.45      0.49       150\n",
      "          29       0.67      0.39      0.49        90\n",
      "          30       0.30      0.40      0.35       150\n",
      "          31       0.57      0.87      0.69       270\n",
      "          32       0.21      0.50      0.29        60\n",
      "          33       0.91      0.75      0.82       210\n",
      "          34       0.87      0.64      0.74       120\n",
      "          35       0.86      0.31      0.46       390\n",
      "          36       1.00      0.40      0.57       120\n",
      "          37       0.94      0.28      0.44        60\n",
      "          38       0.87      0.76      0.81       690\n",
      "          39       0.98      0.67      0.79        90\n",
      "          40       0.88      0.31      0.46        90\n",
      "          41       0.88      0.47      0.61        60\n",
      "          42       0.68      0.70      0.69        90\n",
      "\n",
      "    accuracy                           0.61     12630\n",
      "   macro avg       0.65      0.56      0.58     12630\n",
      "weighted avg       0.66      0.61      0.62     12630\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, Y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6069675376088678\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(Y_test, Y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Validation Set Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_valid = model_3.predict(X_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        30\n",
      "           1       0.48      0.47      0.47       240\n",
      "           2       0.58      0.49      0.53       240\n",
      "           3       0.35      0.47      0.40       150\n",
      "           4       0.42      0.61      0.50       210\n",
      "           5       0.29      0.48      0.36       210\n",
      "           6       0.47      0.83      0.60        60\n",
      "           7       0.31      0.44      0.36       150\n",
      "           8       0.31      0.40      0.35       150\n",
      "           9       0.60      0.34      0.43       150\n",
      "          10       0.55      0.83      0.66       210\n",
      "          11       0.55      0.51      0.53       150\n",
      "          12       0.95      0.85      0.89       210\n",
      "          13       0.92      0.95      0.94       240\n",
      "          14       0.91      0.74      0.82        90\n",
      "          15       0.78      0.31      0.44        90\n",
      "          16       0.35      0.30      0.32        60\n",
      "          17       0.99      1.00      1.00       120\n",
      "          18       0.52      0.45      0.48       120\n",
      "          19       0.44      0.53      0.48        30\n",
      "          20       0.37      0.48      0.42        60\n",
      "          21       0.00      0.00      0.00        60\n",
      "          22       1.00      0.50      0.67        60\n",
      "          23       0.35      0.18      0.24        60\n",
      "          24       0.00      0.00      0.00        30\n",
      "          25       0.81      0.44      0.57       150\n",
      "          26       0.48      0.75      0.58        60\n",
      "          27       0.00      0.00      0.00        30\n",
      "          28       0.36      0.20      0.26        60\n",
      "          29       0.20      0.03      0.06        30\n",
      "          30       0.21      0.37      0.27        60\n",
      "          31       0.55      0.91      0.69        90\n",
      "          32       0.00      0.00      0.00        30\n",
      "          33       0.83      0.33      0.48        90\n",
      "          34       0.74      0.42      0.53        60\n",
      "          35       0.87      0.49      0.63       120\n",
      "          36       0.95      0.33      0.49        60\n",
      "          37       0.80      0.13      0.23        30\n",
      "          38       0.91      0.88      0.89       210\n",
      "          39       1.00      0.77      0.87        30\n",
      "          40       0.89      0.13      0.23        60\n",
      "          41       0.24      0.33      0.28        30\n",
      "          42       0.32      0.40      0.36        30\n",
      "\n",
      "    accuracy                           0.54      4410\n",
      "   macro avg       0.53      0.44      0.45      4410\n",
      "weighted avg       0.59      0.54      0.54      4410\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_validation, Y_pred_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5417233560090703\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(Y_validation, Y_pred_valid)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:54:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=8, num_parallel_tree=1,\n",
       "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Boosting\n",
    "from xgboost import XGBClassifier\n",
    "model_4 = XGBClassifier()\n",
    "model_4.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Training Set Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_train = model_4.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       180\n",
      "           1       1.00      1.00      1.00      1980\n",
      "           2       1.00      1.00      1.00      2010\n",
      "           3       1.00      1.00      1.00      1260\n",
      "           4       1.00      1.00      1.00      1770\n",
      "           5       1.00      1.00      1.00      1650\n",
      "           6       1.00      1.00      1.00       360\n",
      "           7       1.00      1.00      1.00      1290\n",
      "           8       1.00      1.00      1.00      1260\n",
      "           9       1.00      1.00      1.00      1320\n",
      "          10       1.00      1.00      1.00      1800\n",
      "          11       1.00      1.00      1.00      1170\n",
      "          12       1.00      1.00      1.00      1890\n",
      "          13       1.00      1.00      1.00      1920\n",
      "          14       1.00      1.00      1.00       690\n",
      "          15       1.00      1.00      1.00       540\n",
      "          16       1.00      1.00      1.00       360\n",
      "          17       1.00      1.00      1.00       990\n",
      "          18       1.00      1.00      1.00      1080\n",
      "          19       1.00      1.00      1.00       180\n",
      "          20       1.00      1.00      1.00       300\n",
      "          21       1.00      1.00      1.00       270\n",
      "          22       1.00      1.00      1.00       330\n",
      "          23       1.00      1.00      1.00       450\n",
      "          24       1.00      1.00      1.00       240\n",
      "          25       1.00      1.00      1.00      1350\n",
      "          26       1.00      1.00      1.00       540\n",
      "          27       1.00      1.00      1.00       210\n",
      "          28       1.00      1.00      1.00       480\n",
      "          29       1.00      1.00      1.00       240\n",
      "          30       1.00      1.00      1.00       390\n",
      "          31       1.00      1.00      1.00       690\n",
      "          32       1.00      1.00      1.00       210\n",
      "          33       1.00      1.00      1.00       599\n",
      "          34       1.00      1.00      1.00       360\n",
      "          35       1.00      1.00      1.00      1080\n",
      "          36       1.00      1.00      1.00       330\n",
      "          37       1.00      1.00      1.00       180\n",
      "          38       1.00      1.00      1.00      1860\n",
      "          39       1.00      1.00      1.00       270\n",
      "          40       1.00      1.00      1.00       300\n",
      "          41       1.00      1.00      1.00       210\n",
      "          42       1.00      1.00      1.00       210\n",
      "\n",
      "    accuracy                           1.00     34799\n",
      "   macro avg       1.00      1.00      1.00     34799\n",
      "weighted avg       1.00      1.00      1.00     34799\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_train, Y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(Y_pred_train, Y_train)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = model_4.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.68      0.77        60\n",
      "           1       0.84      0.94      0.89       720\n",
      "           2       0.88      0.97      0.92       750\n",
      "           3       0.91      0.94      0.93       450\n",
      "           4       0.96      0.95      0.96       660\n",
      "           5       0.79      0.83      0.81       630\n",
      "           6       0.92      0.65      0.76       150\n",
      "           7       0.90      0.89      0.90       450\n",
      "           8       0.83      0.90      0.87       450\n",
      "           9       0.93      0.99      0.96       480\n",
      "          10       0.95      0.95      0.95       660\n",
      "          11       0.84      0.90      0.86       420\n",
      "          12       0.90      0.92      0.91       690\n",
      "          13       0.96      0.99      0.97       720\n",
      "          14       0.94      0.91      0.93       270\n",
      "          15       0.87      0.84      0.85       210\n",
      "          16       0.98      0.95      0.97       150\n",
      "          17       0.98      0.93      0.95       360\n",
      "          18       0.90      0.78      0.84       390\n",
      "          19       0.58      0.70      0.63        60\n",
      "          20       0.57      0.70      0.63        90\n",
      "          21       0.95      0.40      0.56        90\n",
      "          22       0.90      0.88      0.89       120\n",
      "          23       0.84      0.73      0.78       150\n",
      "          24       0.82      0.60      0.69        90\n",
      "          25       0.92      0.92      0.92       480\n",
      "          26       0.83      0.78      0.81       180\n",
      "          27       0.77      0.50      0.61        60\n",
      "          28       0.76      0.89      0.82       150\n",
      "          29       0.91      0.74      0.82        90\n",
      "          30       0.69      0.56      0.62       150\n",
      "          31       0.78      0.94      0.85       270\n",
      "          32       0.89      0.80      0.84        60\n",
      "          33       0.86      0.87      0.87       210\n",
      "          34       0.98      0.98      0.98       120\n",
      "          35       0.95      0.92      0.94       390\n",
      "          36       0.96      0.91      0.94       120\n",
      "          37       0.96      0.87      0.91        60\n",
      "          38       0.97      0.93      0.95       690\n",
      "          39       0.84      0.66      0.74        90\n",
      "          40       0.87      0.68      0.76        90\n",
      "          41       0.71      0.58      0.64        60\n",
      "          42       0.98      0.67      0.79        90\n",
      "\n",
      "    accuracy                           0.89     12630\n",
      "   macro avg       0.87      0.82      0.84     12630\n",
      "weighted avg       0.89      0.89      0.89     12630\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6069675376088678\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(Y_test, Y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predecting Validation Set Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred_valid = model.predict(X_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.53      0.70        30\n",
      "           1       0.84      0.88      0.86       240\n",
      "           2       0.95      0.88      0.91       240\n",
      "           3       0.86      0.97      0.91       150\n",
      "           4       0.93      0.97      0.95       210\n",
      "           5       0.82      0.80      0.81       210\n",
      "           6       0.75      1.00      0.86        60\n",
      "           7       0.91      0.96      0.94       150\n",
      "           8       0.92      0.90      0.91       150\n",
      "           9       0.97      0.93      0.95       150\n",
      "          10       0.91      1.00      0.95       210\n",
      "          11       0.77      0.93      0.84       150\n",
      "          12       0.82      0.98      0.89       210\n",
      "          13       0.98      1.00      0.99       240\n",
      "          14       1.00      0.99      0.99        90\n",
      "          15       0.96      0.98      0.97        90\n",
      "          16       0.98      0.98      0.98        60\n",
      "          17       0.99      1.00      1.00       120\n",
      "          18       0.78      0.99      0.88       120\n",
      "          19       0.86      0.63      0.73        30\n",
      "          20       0.82      0.47      0.60        60\n",
      "          21       1.00      0.42      0.59        60\n",
      "          22       1.00      0.85      0.92        60\n",
      "          23       0.91      0.82      0.86        60\n",
      "          24       0.00      0.00      0.00        30\n",
      "          25       0.91      0.98      0.95       150\n",
      "          26       0.95      0.97      0.96        60\n",
      "          27       0.81      0.43      0.57        30\n",
      "          28       0.92      1.00      0.96        60\n",
      "          29       0.96      0.83      0.89        30\n",
      "          30       0.75      0.83      0.79        60\n",
      "          31       0.76      1.00      0.86        90\n",
      "          32       0.43      0.33      0.38        30\n",
      "          33       0.99      0.97      0.98        90\n",
      "          34       1.00      1.00      1.00        60\n",
      "          35       0.98      0.98      0.98       120\n",
      "          36       1.00      1.00      1.00        60\n",
      "          37       1.00      1.00      1.00        30\n",
      "          38       0.98      0.96      0.97       210\n",
      "          39       1.00      1.00      1.00        30\n",
      "          40       1.00      0.35      0.52        60\n",
      "          41       1.00      0.50      0.67        30\n",
      "          42       1.00      0.63      0.78        30\n",
      "\n",
      "    accuracy                           0.90      4410\n",
      "   macro avg       0.89      0.83      0.84      4410\n",
      "weighted avg       0.90      0.90      0.89      4410\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_validation, Y_pred_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9004535147392291\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(Y_validation, Y_pred_valid)) "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Traffic Sign Classification-Copy2.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
